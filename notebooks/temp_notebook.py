#!/usr/bin/env python
# coding: utf-8

# # TLOB (Time-weighted Limit Order Book) Fiyat Tahmin Projesi
# 
# Bu notebook, TLOB kÃ¼tÃ¼phanesi kullanarak limit order book verilerinden fiyat tahmini yapan kapsamlÄ± bir analiz projesidir.
# 
# ## Proje Ã–zeti
# - **AmaÃ§**: Limit Order Book verilerinden gelecek fiyat hareketlerini tahmin etmek
# - **Model**: TLOB (Time-weighted Limit Order Book) - Transformer tabanlÄ± model
# - **Veri**: AKBNK hisse senedi LOB verileri
# - **Tahmin TÃ¼rÃ¼**: SÄ±nÄ±flandÄ±rma (YÃ¼kseliÅŸ/Sabit/DÃ¼ÅŸÃ¼ÅŸ)
# 
# ## Ä°Ã§erik
# 1. [Gerekli KÃ¼tÃ¼phanelerin YÃ¼klenmesi](#1-gerekli-kÃ¼tÃ¼phanelerin-yÃ¼klenmesi)
# 2. [KonfigÃ¼rasyon YÃ¼kleme](#2-konfigÃ¼rasyon-yÃ¼kleme)
# 3. [Veri YÃ¼kleme ve Ã–n Ä°ÅŸleme](#3-veri-yÃ¼kleme-ve-Ã¶n-iÅŸleme)
# 4. [TLOB Model Entegrasyonu](#4-tlob-model-entegrasyonu)
# 5. [Model EÄŸitimi](#5-model-eÄŸitimi)
# 6. [Model DeÄŸerlendirmesi](#6-model-deÄŸerlendirmesi)
# 7. [Tahminler ve GÃ¶rselleÅŸtirme](#7-tahminler-ve-gÃ¶rselleÅŸtirme)
# 8. [SonuÃ§lar ve Analiz](#8-sonuÃ§lar-ve-analiz)
# 
# ## âš ï¸ Ã–nemli Not
# Bu notebook'u hÃ¼creleri sÄ±rayla Ã§alÄ±ÅŸtÄ±rÄ±n. Her hÃ¼cre Ã¶nceki hÃ¼crelerin tamamlanmasÄ±nÄ± bekler.

# ## 1. Gerekli KÃ¼tÃ¼phanelerin YÃ¼klenmesi

# In[1]:


# Temel kÃ¼tÃ¼phaneler
import os
import sys
import yaml
import warnings
import glob
import pandas as pd
import numpy as np
from pathlib import Path
import torch
import json
from datetime import datetime

# GÃ¶rselleÅŸtirme kÃ¼tÃ¼phaneleri
import matplotlib.pyplot as plt
import seaborn as sns
from matplotlib import rcParams

# Proje kÃ¶k dizinini bul ve Python path'ine ekle
# Notebook'un bulunduÄŸu dizinden bir Ã¼st dizine Ã§Ä±k (proje kÃ¶kÃ¼)
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.append(project_root)

# UyarÄ±larÄ± kapat
warnings.filterwarnings('ignore')

# Matplotlib ayarlarÄ±
plt.style.use('seaborn-v0_8')
rcParams['figure.figsize'] = (12, 8)
rcParams['font.size'] = 10

print("âœ… KÃ¼tÃ¼phaneler baÅŸarÄ±yla yÃ¼klendi!")
print(f"ğŸ“ Proje kÃ¶k dizini: {project_root}")


# ## 2. KonfigÃ¼rasyon YÃ¼kleme

# In[2]:


def load_config():
    """KonfigÃ¼rasyon dosyasÄ±nÄ± yÃ¼kle"""
    # Proje kÃ¶k dizinindeki config dosyasÄ±nÄ± kullan
    config_path = os.path.join(project_root, 'config', 'config.yaml')
    
    if not os.path.exists(config_path):
        # Alternatif olarak mevcut dizinde ara
        alt_config_path = 'config/config.yaml'
        if os.path.exists(alt_config_path):
            config_path = alt_config_path
        else:
            raise FileNotFoundError(f"KonfigÃ¼rasyon dosyasÄ± bulunamadÄ±: {config_path}")
    
    print(f"ğŸ“‚ KonfigÃ¼rasyon dosyasÄ± yÃ¼kleniyor: {config_path}")
    with open(config_path, 'r') as file:
        return yaml.safe_load(file)

# KonfigÃ¼rasyonu yÃ¼kle
config = load_config()
print("ğŸ“‹ KonfigÃ¼rasyon yÃ¼klendi:")
print(f"   Model tipi: {config['model']['type']}")
print(f"   Hidden dim: {config['model']['hidden_dim']}")
print(f"   Sequence size: {config['model']['seq_size']}")
print(f"   Learning rate: {config['training']['learning_rate']}")
print(f"   Batch size: {config['training']['batch_size']}")
print(f"   Epochs: {config['training']['epochs']}")

# Gerekli dizinleri oluÅŸtur
models_dir = os.path.join(project_root, 'models')
results_dir = os.path.join(project_root, 'results')
os.makedirs(models_dir, exist_ok=True)
os.makedirs(results_dir, exist_ok=True)
print("âœ… Gerekli dizinler oluÅŸturuldu")


# ## 3. Veri YÃ¼kleme ve Ã–n Ä°ÅŸleme

# In[4]:


# Veri yÃ¼kleme sÄ±nÄ±fÄ±nÄ± import et
from src.data_loader import LOBDataLoader

# Veri dosyasÄ±nÄ± bul
data_source = config.get('data', {}).get('data_source', 'data/*.csv')

# Proje kÃ¶k dizinindeki data klasÃ¶rÃ¼nÃ¼ kontrol et
if data_source.endswith('*.csv'):
    # Ã–nce proje kÃ¶k dizininde ara
    data_files = glob.glob(os.path.join(project_root, 'data', '*.csv'))
    if not data_files:
        # Alternatif olarak mevcut dizinde ara
        data_files = glob.glob('data/*.csv')
    
    if not data_files:
        raise FileNotFoundError("âŒ Data dizininde CSV dosyasÄ± bulunamadÄ±!")
    data_path = data_files[0]
else:
    # Mutlak yol kullan
    if not os.path.isabs(data_source):
        data_path = os.path.join(project_root, data_source)
    else:
        data_path = data_source
    
    if not os.path.exists(data_path):
        raise FileNotFoundError(f"âŒ Veri dosyasÄ± bulunamadÄ±: {data_path}")

print(f"ğŸ“Š Veri yÃ¼kleniyor: {data_path}")

# Veriyi yÃ¼kle
data_loader = LOBDataLoader(data_path)
df = data_loader.load_data()

print(f"âœ… Veri yÃ¼klendi: {len(df)} satÄ±r, {len(df.columns)} sÃ¼tun")
print(f"ğŸ“… Tarih aralÄ±ÄŸÄ±: {df['DateTime'].min()} - {df['DateTime'].max()}")
print(f"ğŸ“ˆ Sembol: {data_loader.symbol}")


# In[5]:


# Veri Ã¶zeti
print("ğŸ“Š Veri Ã–zeti:")
print("=" * 50)
print(df.info())
print("\nğŸ“ˆ Ä°lk 5 satÄ±r:")
print(df.head())
print("\nğŸ“‰ Son 5 satÄ±r:")
print(df.tail())


# In[6]:


# Veri istatistikleri
print("ğŸ“Š Veri Ä°statistikleri:")
print("=" * 50)

# Mid price hesapla
df['mid_price'] = (df['Level 1 Bid Price'] + df['Level 1 Ask Price']) / 2

# Fiyat istatistikleri
print(f"ğŸ’° Mid Price Ä°statistikleri:")
print(f"   Ortalama: {df['mid_price'].mean():.4f}")
print(f"   Standart Sapma: {df['mid_price'].std():.4f}")
print(f"   Minimum: {df['mid_price'].min():.4f}")
print(f"   Maksimum: {df['mid_price'].max():.4f}")
print(f"   Medyan: {df['mid_price'].median():.4f}")

# Eksik deÄŸerler
print(f"\nğŸ” Eksik DeÄŸerler:")
missing_data = df.isnull().sum()
print(missing_data[missing_data > 0])


# In[7]:


# Fiyat grafiÄŸi
plt.figure(figsize=(15, 8))
plt.plot(df['DateTime'], df['mid_price'], linewidth=1, alpha=0.8)
plt.title(f'{data_loader.symbol} Mid Price Zaman Serisi', fontsize=16, fontweight='bold')
plt.xlabel('Tarih', fontsize=12)
plt.ylabel('Mid Price (TL)', fontsize=12)
plt.grid(True, alpha=0.3)
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

# Fiyat daÄŸÄ±lÄ±mÄ±
plt.figure(figsize=(12, 5))
plt.subplot(1, 2, 1)
plt.hist(df['mid_price'], bins=50, alpha=0.7, color='skyblue', edgecolor='black')
plt.title('Mid Price DaÄŸÄ±lÄ±mÄ±', fontweight='bold')
plt.xlabel('Mid Price (TL)')
plt.ylabel('Frekans')

plt.subplot(1, 2, 2)
plt.boxplot(df['mid_price'])
plt.title('Mid Price Box Plot', fontweight='bold')
plt.ylabel('Mid Price (TL)')
plt.tight_layout()
plt.show()


# ## 4. TLOB Model Entegrasyonu

# In[8]:


# TLOB entegrasyonunu import et
from src.tlob_integration import TLOBIntegration

# TLOB konfigÃ¼rasyonu
tlob_config = {
    'hidden_dim': config['model']['hidden_dim'],
    'num_layers': config['model']['num_layers'],
    'seq_size': config['model']['seq_size'],
    'num_heads': config['model'].get('num_heads', 1),
    'is_sin_emb': config['model'].get('is_sin_emb', True),
    'lr': config['training']['learning_rate'],
    'batch_size': config['training']['batch_size'],
    'horizon': config['model']['horizon'],
    'forecast_days': config['model']['forecast_days'],
    'early_stopping_patience': config['training']['early_stopping_patience'],
    'min_delta': config['training'].get('min_delta', 0.001),
    'data': {
        'train_split': 0.72,
        'val_split': 0.18,
        'test_split': 0.10
    }
}

print("ğŸ¤– TLOB model entegrasyonu baÅŸlatÄ±lÄ±yor...")
print(f"   Hidden dim: {tlob_config['hidden_dim']}")
print(f"   Num layers: {tlob_config['num_layers']}")
print(f"   Sequence size: {tlob_config['seq_size']}")
print(f"   Learning rate: {tlob_config['lr']}")
print(f"   Batch size: {tlob_config['batch_size']}")

# TLOB entegrasyonunu baÅŸlat
tlob_integration = TLOBIntegration(tlob_config)


# In[ ]:


# Veriyi TLOB iÃ§in hazÄ±rla
print("ğŸ”„ Veri TLOB modeli iÃ§in hazÄ±rlanÄ±yor...")
num_features = tlob_integration.prepare_data(data_path)
print(f"âœ… Veri hazÄ±rlandÄ±: {num_features} Ã¶zellik")

# Model oluÅŸtur
print("\nğŸ—ï¸ Model oluÅŸturuluyor...")
model = tlob_integration.create_model(num_features)
total_params = sum(p.numel() for p in model.parameters())
trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
print(f"âœ… Model oluÅŸturuldu:")
print(f"   Toplam parametre: {total_params:,}")
print(f"   EÄŸitilebilir parametre: {trainable_params:,}")
print(f"   Model boyutu: {total_params * 4 / 1024 / 1024:.2f} MB")


# ## 5. Model EÄŸitimi

# In[2]:


# Model eÄŸitimi
print("ğŸ‹ï¸ Model eÄŸitimi baÅŸlÄ±yor...")
print("=" * 60)

max_epochs = config['training']['epochs']
print(f"ğŸ“Š EÄŸitim parametreleri:")
print(f"   Maksimum epoch: {max_epochs}")
print(f"   Learning rate: {config['training']['learning_rate']}")
print(f"   Batch size: {config['training']['batch_size']}")
print(f"   Early stopping patience: {config['training']['early_stopping_patience']}")
print(f"   Min delta: {config['training'].get('min_delta', 0.001)}")

# EÄŸitimi baÅŸlat
training_history = tlob_integration.train_model(max_epochs=max_epochs)
print("\nâœ… EÄŸitim tamamlandÄ±!")


# In[ ]:


# EÄŸitim geÃ§miÅŸini gÃ¶rselleÅŸtir
if 'training_history' in locals() and training_history:
    print("ğŸ“ˆ EÄŸitim geÃ§miÅŸi gÃ¶rselleÅŸtiriliyor...")
    
    # EÄŸitim ve validasyon loss'larÄ±
    train_losses = [h['train_loss'] for h in training_history]
    val_losses = [h['val_loss'] for h in training_history]
    epochs = range(1, len(train_losses) + 1)
    
    plt.figure(figsize=(15, 5))
    
    plt.subplot(1, 2, 1)
    plt.plot(epochs, train_losses, 'b-', label='EÄŸitim Loss', linewidth=2)
    plt.plot(epochs, val_losses, 'r-', label='Validasyon Loss', linewidth=2)
    plt.title('EÄŸitim ve Validasyon Loss', fontsize=14, fontweight='bold')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    # EÄŸitim ve validasyon accuracy'leri
    train_accs = [h.get('train_acc', 0) for h in training_history]
    val_accs = [h.get('val_acc', 0) for h in training_history]
    
    plt.subplot(1, 2, 2)
    plt.plot(epochs, train_accs, 'b-', label='EÄŸitim Accuracy', linewidth=2)
    plt.plot(epochs, val_accs, 'r-', label='Validasyon Accuracy', linewidth=2)
    plt.title('EÄŸitim ve Validasyon Accuracy', fontsize=14, fontweight='bold')
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy')
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.show()
    
    # Son epoch bilgileri
    print(f"\nğŸ“Š Son Epoch Bilgileri:")
    print(f"   Epoch: {len(training_history)}")
    print(f"   Son eÄŸitim loss: {train_losses[-1]:.4f}")
    print(f"   Son validasyon loss: {val_losses[-1]:.4f}")
    print(f"   Son eÄŸitim accuracy: {train_accs[-1]:.4f}")
    print(f"   Son validasyon accuracy: {val_accs[-1]:.4f}")
else:
    print("âš ï¸ EÄŸitim geÃ§miÅŸi bulunamadÄ±. Ã–nce model eÄŸitimini tamamlayÄ±n.")


# ## 6. Model DeÄŸerlendirmesi

# In[ ]:


# En iyi modeli yÃ¼kle
print("ğŸ“¥ En iyi model yÃ¼kleniyor...")
model_path = os.path.join(project_root, 'models', 'best_tlob_model.pth')
try:
    model.load_state_dict(torch.load(model_path))
    tlob_integration.model = model
    print("âœ… En iyi model yÃ¼klendi")
except FileNotFoundError:
    print(f"âš ï¸ En iyi model dosyasÄ± bulunamadÄ±: {model_path}")
    print("Ã–nce model eÄŸitimini tamamlayÄ±n.")
    raise

# Model performansÄ±nÄ± deÄŸerlendir
print("\nğŸ§ª Model performansÄ± deÄŸerlendiriliyor...")
test_metrics = tlob_integration.evaluate_model()

print("\nğŸ“Š Test Metrikleri:")
print("=" * 50)
for metric_name, metric_value in test_metrics.items():
    if isinstance(metric_value, float):
        print(f"   {metric_name}: {metric_value:.4f}")
    else:
        print(f"   {metric_name}: {metric_value}")


# In[ ]:


# Test metriklerini kaydet
tlob_integration.save_test_metrics(test_metrics)
print("âœ… Test metrikleri kaydedildi")

# Metrikleri gÃ¶rselleÅŸtir
print("\nğŸ“Š Metrik gÃ¶rselleÅŸtirmeleri oluÅŸturuluyor...")

# SÄ±nÄ±f daÄŸÄ±lÄ±mÄ±
if 'class_distribution' in test_metrics:
    class_dist = test_metrics['class_distribution']
    classes = ['DÃ¼ÅŸÃ¼ÅŸ', 'Sabit', 'YÃ¼kseliÅŸ']
    
    plt.figure(figsize=(10, 6))
    bars = plt.bar(classes, [class_dist.get(str(i), 0) for i in range(3)], 
                   color=['red', 'gray', 'green'], alpha=0.7)
    plt.title('Test Verisi SÄ±nÄ±f DaÄŸÄ±lÄ±mÄ±', fontsize=14, fontweight='bold')
    plt.xlabel('SÄ±nÄ±f')
    plt.ylabel('Ã–rnek SayÄ±sÄ±')
    
    # DeÄŸerleri Ã§ubuklarÄ±n Ã¼zerine yaz
    for bar, value in zip(bars, [class_dist.get(str(i), 0) for i in range(3)]):
        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, 
                str(value), ha='center', va='bottom', fontweight='bold')
    
    plt.tight_layout()
    plt.show()

# Confusion matrix
if 'confusion_matrix' in test_metrics:
    cm = test_metrics['confusion_matrix']
    
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
                xticklabels=classes, yticklabels=classes)
    plt.title('Confusion Matrix', fontsize=14, fontweight='bold')
    plt.xlabel('Tahmin Edilen SÄ±nÄ±f')
    plt.ylabel('GerÃ§ek SÄ±nÄ±f')
    plt.tight_layout()
    plt.show()


# ## 7. Tahminler ve GÃ¶rselleÅŸtirme

# In[ ]:


# Test verisi Ã¼zerinde tahminler yap
print("ğŸ”® Tahminler yapÄ±lÄ±yor...")

# Test verisi al
test_loader = tlob_integration.data_module.test_dataloader()
test_batch = next(iter(test_loader))
test_data = test_batch[0]  # Ä°lk batch verisi
test_labels = test_batch[1]  # Ä°lk batch etiketleri

# Tek tahmin
print("\nğŸ“Š Tek tahmin Ã¶rneÄŸi:")
prediction, probabilities = tlob_integration.predict(test_data[0].numpy())
direction_map = {0: "YÃ¼kseliÅŸ", 1: "Sabit", 2: "DÃ¼ÅŸÃ¼ÅŸ"}
print(f"   Tahmin: {direction_map[prediction]} (SÄ±nÄ±f {prediction})")
print(f"   GÃ¼ven: {np.max(probabilities):.2%}")
print(f"   TÃ¼m olasÄ±lÄ±klar: {probabilities}")


# In[ ]:


# N-gÃ¼nlÃ¼k tahmin
forecast_days = config['model']['forecast_days']
print(f"\nğŸ“… {forecast_days} gÃ¼nlÃ¼k tahmin oluÅŸturuluyor...")
forecast = tlob_integration.predict_days(test_data.numpy())

# Tahmin sonuÃ§larÄ±nÄ± gÃ¶ster
print(f"\n{forecast_days} GÃ¼nlÃ¼k Mid Price Tahmin SonuÃ§larÄ±:")
print("=" * 70)

for day_result in forecast:
    day = day_result['day']
    pred = day_result['prediction']
    conf = day_result['confidence']
    mid_price = day_result['mid_price'].item() if hasattr(day_result['mid_price'], 'item') else float(day_result['mid_price'])
    change_pct = day_result['price_change_pct'].item() if hasattr(day_result['price_change_pct'], 'item') else float(day_result['price_change_pct'])
    direction = direction_map[pred]
    
    print(f"  GÃ¼n {day:2d}: {direction:8s} | Mid Price: {mid_price:8.4f} | DeÄŸiÅŸim: {change_pct:+6.2f}% | GÃ¼ven: {conf:6.2%}")

print("=" * 70)


# In[ ]:


# Tahmin gÃ¶rselleÅŸtirmeleri
print("\nğŸ“Š Tahmin gÃ¶rselleÅŸtirmeleri oluÅŸturuluyor...")

# GÃ¶rselleÅŸtirme sÄ±nÄ±fÄ±nÄ± import et
from src.visualization import LOBVisualizer
viz = LOBVisualizer()

# EÄŸitim geÃ§miÅŸi
print("ğŸ“ˆ EÄŸitim geÃ§miÅŸi Ã§iziliyor...")
viz.plot_training_history(tlob_integration)

# Fiyat evrimi
print("ğŸ“Š Fiyat evrimi Ã§iziliyor...")
viz.plot_price_evolution(data_loader)

# Tahmin grafiÄŸi
print("ğŸ”® Tahmin grafiÄŸi Ã§iziliyor...")
viz.plot_forecast(forecast)

print("âœ… TÃ¼m gÃ¶rselleÅŸtirmeler tamamlandÄ±!")


# ## 8. SonuÃ§lar ve Analiz

# In[ ]:


# Proje Ã¶zeti
print("ğŸ‰ TLOB Fiyat Tahmin Projesi TamamlandÄ±!")
print("=" * 60)

print(f"ğŸ“Š Proje Ã–zeti:")
print(f"   Veri kaynaÄŸÄ±: {data_path}")
print(f"   Toplam veri: {len(df):,} satÄ±r")
print(f"   Model tipi: {config['model']['type']}")
print(f"   Model parametreleri: {total_params:,}")
print(f"   EÄŸitim epoch'larÄ±: {len(training_history) if 'training_history' in locals() else 'N/A'}")
print(f"   Test accuracy: {test_metrics.get('accuracy', 'N/A'):.4f}")
print(f"   Test precision: {test_metrics.get('precision', 'N/A'):.4f}")
print(f"   Test recall: {test_metrics.get('recall', 'N/A'):.4f}")
print(f"   Test f1_score: {test_metrics.get('f1_score', 'N/A'):.4f}")

print(f"\nğŸ“ Kaydedilen Dosyalar:")
print(f"   Model: {os.path.join(project_root, 'models', 'best_tlob_model.pth')}")
print(f"   Test metrikleri: {os.path.join(project_root, 'results', 'test_metrics.json')}")
print(f"   GÃ¶rselleÅŸtirmeler: {os.path.join(project_root, 'results')}")

print(f"\nğŸ”® Tahmin Ã–zeti:")
up_count = sum(1 for f in forecast if f['prediction'] == 0)
stable_count = sum(1 for f in forecast if f['prediction'] == 1)
down_count = sum(1 for f in forecast if f['prediction'] == 2)
print(f"   YÃ¼kseliÅŸ tahmini: {up_count} gÃ¼n")
print(f"   Sabit tahmini: {stable_count} gÃ¼n")
print(f"   DÃ¼ÅŸÃ¼ÅŸ tahmini: {down_count} gÃ¼n")

print("\nâœ… Analiz tamamlandÄ±! SonuÃ§lar 'results/' dizininde kaydedildi.")


# In[ ]:


# SonuÃ§larÄ± JSON olarak kaydet
final_results = {
    'project_info': {
        'name': 'TLOB Price Prediction Project',
        'date': datetime.now().isoformat(),
        'data_source': data_path,
        'total_data_points': len(df),
        'model_type': config['model']['type']
    },
    'model_config': config,
    'training_summary': {
        'total_epochs': len(training_history) if 'training_history' in locals() else 0,
        'final_train_loss': training_history[-1]['train_loss'] if 'training_history' in locals() and training_history else None,
        'final_val_loss': training_history[-1]['val_loss'] if 'training_history' in locals() and training_history else None,
        'model_parameters': total_params
    },
    'test_metrics': test_metrics,
    'forecast_summary': {
        'forecast_days': forecast_days,
        'predictions': [{
            'day': f['day'],
            'prediction': direction_map[f['prediction']],
            'confidence': float(f['confidence']),
            'mid_price': float(f['mid_price']),
            'price_change_pct': float(f['price_change_pct'])
        } for f in forecast]
    }
}

# JSON dosyasÄ±na kaydet
results_file = os.path.join(project_root, 'results', 'final_analysis_results.json')
with open(results_file, 'w', encoding='utf-8') as f:
    json.dump(final_results, f, indent=2, ensure_ascii=False)

print(f"âœ… Final analiz sonuÃ§larÄ± kaydedildi: {results_file}")

