{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0693e097",
   "metadata": {},
   "source": [
    "# TLOB (Time-weighted Limit Order Book) Fiyat Tahmin Projesi\n",
    "\n",
    "Bu notebook, TLOB kütüphanesi kullanarak limit order book verilerinden fiyat tahmini yapan kapsamlı bir analiz projesidir.\n",
    "\n",
    "## Proje Özeti\n",
    "- **Amaç**: Limit Order Book verilerinden gelecek fiyat hareketlerini tahmin etmek\n",
    "- **Model**: TLOB (Time-weighted Limit Order Book) - Transformer tabanlı model\n",
    "- **Veri**: AKBNK hisse senedi LOB verileri\n",
    "- **Tahmin Türü**: Sınıflandırma (Yükseliş/Sabit/Düşüş)\n",
    "\n",
    "## İçerik\n",
    "1. [Gerekli Kütüphanelerin Yüklenmesi](#1-gerekli-kütüphanelerin-yüklenmesi)\n",
    "2. [Konfigürasyon Yükleme](#2-konfigürasyon-yükleme)\n",
    "3. [Veri Yükleme ve Ön İşleme](#3-veri-yükleme-ve-ön-işleme)\n",
    "4. [TLOB Model Entegrasyonu](#4-tlob-model-entegrasyonu)\n",
    "5. [Model Eğitimi](#5-model-eğitimi)\n",
    "6. [Model Değerlendirmesi](#6-model-değerlendirmesi)\n",
    "7. [Tahminler ve Görselleştirme](#7-tahminler-ve-görselleştirme)\n",
    "8. [Sonuçlar ve Analiz](#8-sonuçlar-ve-analiz)\n",
    "\n",
    "## ⚠️ Önemli Not\n",
    "Bu notebook'u hücreleri sırayla çalıştırın. Her hücre önceki hücrelerin tamamlanmasını bekler."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d34124",
   "metadata": {},
   "source": [
    "## 1. Gerekli Kütüphanelerin Yüklenmesi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708c9a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temel kütüphaneler\n",
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "import warnings\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Görselleştirme kütüphaneleri\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib import rcParams\n",
    "\n",
    "# Proje kök dizinini bul ve Python path'ine ekle\n",
    "# Notebook'un bulunduğu dizinden bir üst dizine çık (proje kökü)\n",
    "project_root = os.path.dirname(os.path.abspath('.'))\n",
    "# project_root = os.path.dirname(notebook_dir)  # notebooks/ dizininden bir üst\n",
    "sys.path.append(project_root)\n",
    "\n",
    "# Uyarıları kapat\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Matplotlib ayarları\n",
    "plt.style.use('seaborn-v0_8')\n",
    "rcParams['figure.figsize'] = (12, 8)\n",
    "rcParams['font.size'] = 10\n",
    "\n",
    "print(\"✅ Kütüphaneler başarıyla yüklendi!\")\n",
    "print(f\"📁 Proje kök dizini: {project_root}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9659ab9",
   "metadata": {},
   "source": [
    "## 2. Konfigürasyon Yükleme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9b7232",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_config():\n",
    "    \"\"\"Konfigürasyon dosyasını yükle\"\"\"\n",
    "    # Proje kök dizinindeki config dosyasını kullan\n",
    "    config_path = os.path.join(project_root, 'config', 'config.yaml')\n",
    "    \n",
    "    if not os.path.exists(config_path):\n",
    "        # Alternatif olarak mevcut dizinde ara\n",
    "        alt_config_path = 'config/config.yaml'\n",
    "        if os.path.exists(alt_config_path):\n",
    "            config_path = alt_config_path\n",
    "        else:\n",
    "            raise FileNotFoundError(f\"Konfigürasyon dosyası bulunamadı: {config_path}\")\n",
    "    \n",
    "    print(f\"📂 Konfigürasyon dosyası yükleniyor: {config_path}\")\n",
    "    with open(config_path, 'r') as file:\n",
    "        return yaml.safe_load(file)\n",
    "\n",
    "# Konfigürasyonu yükle\n",
    "config = load_config()\n",
    "print(\"📋 Konfigürasyon yüklendi:\")\n",
    "print(f\"   Model tipi: {config['model']['type']}\")\n",
    "print(f\"   Hidden dim: {config['model']['hidden_dim']}\")\n",
    "print(f\"   Sequence size: {config['model']['seq_size']}\")\n",
    "print(f\"   Learning rate: {config['training']['learning_rate']}\")\n",
    "print(f\"   Batch size: {config['training']['batch_size']}\")\n",
    "print(f\"   Epochs: {config['training']['epochs']}\")\n",
    "\n",
    "# Gerekli dizinleri oluştur\n",
    "models_dir = os.path.join(project_root, 'models')\n",
    "results_dir = os.path.join(project_root, 'results')\n",
    "os.makedirs(models_dir, exist_ok=True)\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "print(\"✅ Gerekli dizinler oluşturuldu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee20b925",
   "metadata": {},
   "source": [
    "## 3. Veri Yükleme ve Ön İşleme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26784ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veri yükleme sınıfını import et\n",
    "from src.data_loader import LOBDataLoader\n",
    "\n",
    "# Veri dosyasını bul\n",
    "data_source = config.get('data', {}).get('data_source', 'data/*.csv')\n",
    "\n",
    "# Proje kök dizinindeki data klasörünü kontrol et\n",
    "if data_source.endswith('*.csv'):\n",
    "    # Önce proje kök dizininde ara\n",
    "    data_files = glob.glob(os.path.join(project_root, 'data', '*.csv'))\n",
    "    if not data_files:\n",
    "        # Alternatif olarak mevcut dizinde ara\n",
    "        data_files = glob.glob('data/*.csv')\n",
    "    \n",
    "    if not data_files:\n",
    "        raise FileNotFoundError(\"❌ Data dizininde CSV dosyası bulunamadı!\")\n",
    "    data_path = data_files[0]\n",
    "else:\n",
    "    # Mutlak yol kullan\n",
    "    if not os.path.isabs(data_source):\n",
    "        data_path = os.path.join(project_root, data_source)\n",
    "    else:\n",
    "        data_path = data_source\n",
    "    \n",
    "    if not os.path.exists(data_path):\n",
    "        raise FileNotFoundError(f\"❌ Veri dosyası bulunamadı: {data_path}\")\n",
    "\n",
    "print(f\"📊 Veri yükleniyor: {data_path}\")\n",
    "\n",
    "# Veriyi yükle\n",
    "data_loader = LOBDataLoader(data_path)\n",
    "df = data_loader.load_data()\n",
    "\n",
    "print(f\"✅ Veri yüklendi: {len(df)} satır, {len(df.columns)} sütun\")\n",
    "print(f\"📅 Tarih aralığı: {df['DateTime'].min()} - {df['DateTime'].max()}\")\n",
    "print(f\"📈 Sembol: {data_loader.symbol}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b0cc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veri özeti\n",
    "print(\"📊 Veri Özeti:\")\n",
    "print(\"=\" * 50)\n",
    "print(df.info())\n",
    "print(\"\\n📈 İlk 5 satır:\")\n",
    "print(df.head())\n",
    "print(\"\\n📉 Son 5 satır:\")\n",
    "print(df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ca9d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veri istatistikleri\n",
    "print(\"📊 Veri İstatistikleri:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Mid price hesapla\n",
    "df['mid_price'] = (df['Level 1 Bid Price'] + df['Level 1 Ask Price']) / 2\n",
    "\n",
    "# Fiyat istatistikleri\n",
    "print(f\"💰 Mid Price İstatistikleri:\")\n",
    "print(f\"   Ortalama: {df['mid_price'].mean():.4f}\")\n",
    "print(f\"   Standart Sapma: {df['mid_price'].std():.4f}\")\n",
    "print(f\"   Minimum: {df['mid_price'].min():.4f}\")\n",
    "print(f\"   Maksimum: {df['mid_price'].max():.4f}\")\n",
    "print(f\"   Medyan: {df['mid_price'].median():.4f}\")\n",
    "\n",
    "# Eksik değerler\n",
    "print(f\"\\n🔍 Eksik Değerler:\")\n",
    "missing_data = df.isnull().sum()\n",
    "print(missing_data[missing_data > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77db0f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fiyat grafiği\n",
    "plt.figure(figsize=(15, 8))\n",
    "plt.plot(df['DateTime'], df['mid_price'], linewidth=1, alpha=0.8)\n",
    "plt.title(f'{data_loader.symbol} Mid Price Zaman Serisi', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Tarih', fontsize=12)\n",
    "plt.ylabel('Mid Price (TL)', fontsize=12)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Fiyat dağılımı\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(df['mid_price'], bins=50, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "plt.title('Mid Price Dağılımı', fontweight='bold')\n",
    "plt.xlabel('Mid Price (TL)')\n",
    "plt.ylabel('Frekans')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.boxplot(df['mid_price'])\n",
    "plt.title('Mid Price Box Plot', fontweight='bold')\n",
    "plt.ylabel('Mid Price (TL)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43d3bc6",
   "metadata": {},
   "source": [
    "## 4. TLOB Model Entegrasyonu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97fb1db3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🤖 TLOB model entegrasyonu başlatılıyor...\n",
      "   Hidden dim: 64\n",
      "   Num layers: 3\n",
      "   Sequence size: 64\n",
      "   Learning rate: 0.0001\n",
      "   Batch size: 512\n"
     ]
    }
   ],
   "source": [
    "# TLOB entegrasyonunu import et\n",
    "from src.tlob_integration import TLOBIntegration\n",
    "\n",
    "# TLOB konfigürasyonu\n",
    "tlob_config = {\n",
    "    'hidden_dim': config['model']['hidden_dim'],\n",
    "    'num_layers': config['model']['num_layers'],\n",
    "    'seq_size': config['model']['seq_size'],\n",
    "    'num_heads': config['model'].get('num_heads', 1),\n",
    "    'is_sin_emb': config['model'].get('is_sin_emb', True),\n",
    "    'lr': config['training']['learning_rate'],\n",
    "    'batch_size': config['training']['batch_size'],\n",
    "    'horizon': config['model']['horizon'],\n",
    "    'forecast_days': config['model']['forecast_days'],\n",
    "    'early_stopping_patience': config['training']['early_stopping_patience'],\n",
    "    'min_delta': config['training'].get('min_delta', 0.001),\n",
    "    'data': {\n",
    "        'train_split': 0.72,\n",
    "        'val_split': 0.18,\n",
    "        'test_split': 0.10\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"🤖 TLOB model entegrasyonu başlatılıyor...\")\n",
    "print(f\"   Hidden dim: {tlob_config['hidden_dim']}\")\n",
    "print(f\"   Num layers: {tlob_config['num_layers']}\")\n",
    "print(f\"   Sequence size: {tlob_config['seq_size']}\")\n",
    "print(f\"   Learning rate: {tlob_config['lr']}\")\n",
    "print(f\"   Batch size: {tlob_config['batch_size']}\")\n",
    "\n",
    "# TLOB entegrasyonunu başlat\n",
    "tlob_integration = TLOBIntegration(tlob_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f38ae5e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 Veri TLOB modeli için hazırlanıyor...\n",
      "📊 Price Analysis:\n",
      "   Bid Price range: 69.00 - 71.50\n",
      "   Ask Price range: 69.05 - 71.55\n",
      "   Mid Price range: 69.03 - 71.53\n",
      "   Sample mid prices: [70.85, 70.875, 70.92500000000001, 70.92500000000001, 70.92500000000001]\n",
      "📊 Data Split Information:\n",
      "   Total features: 28,784\n",
      "   Train features: 20,724 (72%)\n",
      "   Val features: 5,181 (18%)\n",
      "   Test features: 2,879 (10%)\n",
      "   Data source: /Users/tolgacoskun-mac/Source/tlob-training/data/2025-07-11-AKBNK-10.csv\n",
      "✅ Veri hazırlandı: 47 özellik\n",
      "\n",
      "🏗️ Model oluşturuluyor...\n",
      "✅ Model oluşturuldu:\n",
      "   Toplam parametre: 2,172,358\n",
      "   Eğitilebilir parametre: 2,172,358\n",
      "   Model boyutu: 8.29 MB\n"
     ]
    }
   ],
   "source": [
    "# Veriyi TLOB için hazırla\n",
    "print(\"🔄 Veri TLOB modeli için hazırlanıyor...\")\n",
    "num_features = tlob_integration.prepare_data(data_path)\n",
    "print(f\"✅ Veri hazırlandı: {num_features} özellik\")\n",
    "\n",
    "# Model oluştur\n",
    "print(\"\\n🏗️ Model oluşturuluyor...\")\n",
    "model = tlob_integration.create_model(num_features)\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"✅ Model oluşturuldu:\")\n",
    "print(f\"   Toplam parametre: {total_params:,}\")\n",
    "print(f\"   Eğitilebilir parametre: {trainable_params:,}\")\n",
    "print(f\"   Model boyutu: {total_params * 4 / 1024 / 1024:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453e43da",
   "metadata": {},
   "source": [
    "## 5. Model Eğitimi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21563ba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏋️ Model eğitimi başlıyor...\n",
      "============================================================\n",
      "📊 Eğitim parametreleri:\n",
      "   Maksimum epoch: 1\n",
      "   Learning rate: 0.0001\n",
      "   Batch size: 512\n",
      "   Early stopping patience: 15\n",
      "   Min delta: 0.001\n",
      "🚀 Starting training with early stopping (patience: 15, min_delta: 0.001)\n",
      "📊 Training for max 1 epochs with learning rate: 0.0001\n"
     ]
    }
   ],
   "source": [
    "# Model eğitimi\n",
    "print(\"🏋️ Model eğitimi başlıyor...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "max_epochs = config['training']['epochs']\n",
    "print(f\"📊 Eğitim parametreleri:\")\n",
    "print(f\"   Maksimum epoch: {max_epochs}\")\n",
    "print(f\"   Learning rate: {config['training']['learning_rate']}\")\n",
    "print(f\"   Batch size: {config['training']['batch_size']}\")\n",
    "print(f\"   Early stopping patience: {config['training']['early_stopping_patience']}\")\n",
    "print(f\"   Min delta: {config['training'].get('min_delta', 0.001)}\")\n",
    "\n",
    "# Eğitimi başlat\n",
    "training_history = tlob_integration.train_model(max_epochs=max_epochs)\n",
    "print(\"\\n✅ Eğitim tamamlandı!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a61f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eğitim geçmişini görselleştir\n",
    "if 'training_history' in locals() and training_history:\n",
    "    print(\"📈 Eğitim geçmişi görselleştiriliyor...\")\n",
    "    \n",
    "    # Eğitim ve validasyon loss'ları\n",
    "    train_losses = [h['train_loss'] for h in training_history]\n",
    "    val_losses = [h['val_loss'] for h in training_history]\n",
    "    epochs = range(1, len(train_losses) + 1)\n",
    "    \n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, train_losses, 'b-', label='Eğitim Loss', linewidth=2)\n",
    "    plt.plot(epochs, val_losses, 'r-', label='Validasyon Loss', linewidth=2)\n",
    "    plt.title('Eğitim ve Validasyon Loss', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Eğitim ve validasyon accuracy'leri\n",
    "    train_accs = [h.get('train_acc', 0) for h in training_history]\n",
    "    val_accs = [h.get('val_acc', 0) for h in training_history]\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, train_accs, 'b-', label='Eğitim Accuracy', linewidth=2)\n",
    "    plt.plot(epochs, val_accs, 'r-', label='Validasyon Accuracy', linewidth=2)\n",
    "    plt.title('Eğitim ve Validasyon Accuracy', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Son epoch bilgileri\n",
    "    print(f\"\\n📊 Son Epoch Bilgileri:\")\n",
    "    print(f\"   Epoch: {len(training_history)}\")\n",
    "    print(f\"   Son eğitim loss: {train_losses[-1]:.4f}\")\n",
    "    print(f\"   Son validasyon loss: {val_losses[-1]:.4f}\")\n",
    "    print(f\"   Son eğitim accuracy: {train_accs[-1]:.4f}\")\n",
    "    print(f\"   Son validasyon accuracy: {val_accs[-1]:.4f}\")\n",
    "else:\n",
    "    print(\"⚠️ Eğitim geçmişi bulunamadı. Önce model eğitimini tamamlayın.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084bc2a1",
   "metadata": {},
   "source": [
    "## 6. Model Değerlendirmesi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4dbdd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# En iyi modeli yükle\n",
    "print(\"📥 En iyi model yükleniyor...\")\n",
    "model_path = os.path.join(project_root, 'models', 'best_tlob_model.pth')\n",
    "try:\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    tlob_integration.model = model\n",
    "    print(\"✅ En iyi model yüklendi\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"⚠️ En iyi model dosyası bulunamadı: {model_path}\")\n",
    "    print(\"Önce model eğitimini tamamlayın.\")\n",
    "    raise\n",
    "\n",
    "# Model performansını değerlendir\n",
    "print(\"\\n🧪 Model performansı değerlendiriliyor...\")\n",
    "test_metrics = tlob_integration.evaluate_model()\n",
    "\n",
    "print(\"\\n📊 Test Metrikleri:\")\n",
    "print(\"=\" * 50)\n",
    "for metric_name, metric_value in test_metrics.items():\n",
    "    if isinstance(metric_value, float):\n",
    "        print(f\"   {metric_name}: {metric_value:.4f}\")\n",
    "    else:\n",
    "        print(f\"   {metric_name}: {metric_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ae000b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test metriklerini kaydet\n",
    "tlob_integration.save_test_metrics(test_metrics)\n",
    "print(\"✅ Test metrikleri kaydedildi\")\n",
    "\n",
    "# Metrikleri görselleştir\n",
    "print(\"\\n📊 Metrik görselleştirmeleri oluşturuluyor...\")\n",
    "\n",
    "# Sınıf dağılımı\n",
    "if 'class_distribution' in test_metrics:\n",
    "    class_dist = test_metrics['class_distribution']\n",
    "    classes = ['Düşüş', 'Sabit', 'Yükseliş']\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    bars = plt.bar(classes, [class_dist.get(str(i), 0) for i in range(3)], \n",
    "                   color=['red', 'gray', 'green'], alpha=0.7)\n",
    "    plt.title('Test Verisi Sınıf Dağılımı', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Sınıf')\n",
    "    plt.ylabel('Örnek Sayısı')\n",
    "    \n",
    "    # Değerleri çubukların üzerine yaz\n",
    "    for bar, value in zip(bars, [class_dist.get(str(i), 0) for i in range(3)]):\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, \n",
    "                str(value), ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Confusion matrix\n",
    "if 'confusion_matrix' in test_metrics:\n",
    "    cm = test_metrics['confusion_matrix']\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=classes, yticklabels=classes)\n",
    "    plt.title('Confusion Matrix', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Tahmin Edilen Sınıf')\n",
    "    plt.ylabel('Gerçek Sınıf')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4434a75",
   "metadata": {},
   "source": [
    "## 7. Tahminler ve Görselleştirme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8dcbd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test verisi üzerinde tahminler yap\n",
    "print(\"🔮 Tahminler yapılıyor...\")\n",
    "\n",
    "# Test verisi al\n",
    "test_loader = tlob_integration.data_module.test_dataloader()\n",
    "test_batch = next(iter(test_loader))\n",
    "test_data = test_batch[0]  # İlk batch verisi\n",
    "test_labels = test_batch[1]  # İlk batch etiketleri\n",
    "\n",
    "# Tek tahmin\n",
    "print(\"\\n📊 Tek tahmin örneği:\")\n",
    "prediction, probabilities = tlob_integration.predict(test_data[0].numpy())\n",
    "direction_map = {0: \"Yükseliş\", 1: \"Sabit\", 2: \"Düşüş\"}\n",
    "print(f\"   Tahmin: {direction_map[prediction]} (Sınıf {prediction})\")\n",
    "print(f\"   Güven: {np.max(probabilities):.2%}\")\n",
    "print(f\"   Tüm olasılıklar: {probabilities}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b367aac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# N-günlük tahmin\n",
    "forecast_days = config['model']['forecast_days']\n",
    "print(f\"\\n📅 {forecast_days} günlük tahmin oluşturuluyor...\")\n",
    "forecast = tlob_integration.predict_days(test_data.numpy())\n",
    "\n",
    "# Tahmin sonuçlarını göster\n",
    "print(f\"\\n{forecast_days} Günlük Mid Price Tahmin Sonuçları:\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for day_result in forecast:\n",
    "    day = day_result['day']\n",
    "    pred = day_result['prediction']\n",
    "    conf = day_result['confidence']\n",
    "    mid_price = day_result['mid_price'].item() if hasattr(day_result['mid_price'], 'item') else float(day_result['mid_price'])\n",
    "    change_pct = day_result['price_change_pct'].item() if hasattr(day_result['price_change_pct'], 'item') else float(day_result['price_change_pct'])\n",
    "    direction = direction_map[pred]\n",
    "    \n",
    "    print(f\"  Gün {day:2d}: {direction:8s} | Mid Price: {mid_price:8.4f} | Değişim: {change_pct:+6.2f}% | Güven: {conf:6.2%}\")\n",
    "\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e1da99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tahmin görselleştirmeleri\n",
    "print(\"\\n📊 Tahmin görselleştirmeleri oluşturuluyor...\")\n",
    "\n",
    "# Görselleştirme sınıfını import et\n",
    "from src.visualization import LOBVisualizer\n",
    "viz = LOBVisualizer()\n",
    "\n",
    "# Eğitim geçmişi\n",
    "print(\"📈 Eğitim geçmişi çiziliyor...\")\n",
    "viz.plot_training_history(tlob_integration)\n",
    "\n",
    "# Fiyat evrimi\n",
    "print(\"📊 Fiyat evrimi çiziliyor...\")\n",
    "viz.plot_price_evolution(data_loader)\n",
    "\n",
    "# Tahmin grafiği\n",
    "print(\"🔮 Tahmin grafiği çiziliyor...\")\n",
    "viz.plot_forecast(forecast)\n",
    "\n",
    "print(\"✅ Tüm görselleştirmeler tamamlandı!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae55711",
   "metadata": {},
   "source": [
    "## 8. Sonuçlar ve Analiz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b935c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proje özeti\n",
    "print(\"🎉 TLOB Fiyat Tahmin Projesi Tamamlandı!\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"📊 Proje Özeti:\")\n",
    "print(f\"   Veri kaynağı: {data_path}\")\n",
    "print(f\"   Toplam veri: {len(df):,} satır\")\n",
    "print(f\"   Model tipi: {config['model']['type']}\")\n",
    "print(f\"   Model parametreleri: {total_params:,}\")\n",
    "print(f\"   Eğitim epoch'ları: {len(training_history) if 'training_history' in locals() else 'N/A'}\")\n",
    "print(f\"   Test accuracy: {test_metrics.get('accuracy', 'N/A'):.4f}\")\n",
    "print(f\"   Test precision: {test_metrics.get('precision', 'N/A'):.4f}\")\n",
    "print(f\"   Test recall: {test_metrics.get('recall', 'N/A'):.4f}\")\n",
    "print(f\"   Test f1_score: {test_metrics.get('f1_score', 'N/A'):.4f}\")\n",
    "\n",
    "print(f\"\\n📁 Kaydedilen Dosyalar:\")\n",
    "print(f\"   Model: {os.path.join(project_root, 'models', 'best_tlob_model.pth')}\")\n",
    "print(f\"   Test metrikleri: {os.path.join(project_root, 'results', 'test_metrics.json')}\")\n",
    "print(f\"   Görselleştirmeler: {os.path.join(project_root, 'results')}\")\n",
    "\n",
    "print(f\"\\n🔮 Tahmin Özeti:\")\n",
    "up_count = sum(1 for f in forecast if f['prediction'] == 0)\n",
    "stable_count = sum(1 for f in forecast if f['prediction'] == 1)\n",
    "down_count = sum(1 for f in forecast if f['prediction'] == 2)\n",
    "print(f\"   Yükseliş tahmini: {up_count} gün\")\n",
    "print(f\"   Sabit tahmini: {stable_count} gün\")\n",
    "print(f\"   Düşüş tahmini: {down_count} gün\")\n",
    "\n",
    "print(\"\\n✅ Analiz tamamlandı! Sonuçlar 'results/' dizininde kaydedildi.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0fbcb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sonuçları JSON olarak kaydet\n",
    "final_results = {\n",
    "    'project_info': {\n",
    "        'name': 'TLOB Price Prediction Project',\n",
    "        'date': datetime.now().isoformat(),\n",
    "        'data_source': data_path,\n",
    "        'total_data_points': len(df),\n",
    "        'model_type': config['model']['type']\n",
    "    },\n",
    "    'model_config': config,\n",
    "    'training_summary': {\n",
    "        'total_epochs': len(training_history) if 'training_history' in locals() else 0,\n",
    "        'final_train_loss': training_history[-1]['train_loss'] if 'training_history' in locals() and training_history else None,\n",
    "        'final_val_loss': training_history[-1]['val_loss'] if 'training_history' in locals() and training_history else None,\n",
    "        'model_parameters': total_params\n",
    "    },\n",
    "    'test_metrics': test_metrics,\n",
    "    'forecast_summary': {\n",
    "        'forecast_days': forecast_days,\n",
    "        'predictions': [{\n",
    "            'day': f['day'],\n",
    "            'prediction': direction_map[f['prediction']],\n",
    "            'confidence': float(f['confidence']),\n",
    "            'mid_price': float(f['mid_price']),\n",
    "            'price_change_pct': float(f['price_change_pct'])\n",
    "        } for f in forecast]\n",
    "    }\n",
    "}\n",
    "\n",
    "# JSON dosyasına kaydet\n",
    "results_file = os.path.join(project_root, 'results', 'final_analysis_results.json')\n",
    "with open(results_file, 'w', encoding='utf-8') as f:\n",
    "    json.dump(final_results, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"✅ Final analiz sonuçları kaydedildi: {results_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
