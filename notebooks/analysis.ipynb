{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0693e097",
   "metadata": {},
   "source": [
    "# TLOB (Time-weighted Limit Order Book) Fiyat Tahmin Projesi\n",
    "\n",
    "Bu notebook, TLOB kÃ¼tÃ¼phanesi kullanarak limit order book verilerinden fiyat tahmini yapan kapsamlÄ± bir analiz projesidir.\n",
    "\n",
    "## Proje Ã–zeti\n",
    "- **AmaÃ§**: Limit Order Book verilerinden gelecek fiyat hareketlerini tahmin etmek\n",
    "- **Model**: TLOB (Time-weighted Limit Order Book) - Transformer tabanlÄ± model\n",
    "- **Veri**: AKBNK hisse senedi LOB verileri\n",
    "- **Tahmin TÃ¼rÃ¼**: SÄ±nÄ±flandÄ±rma (YÃ¼kseliÅŸ/Sabit/DÃ¼ÅŸÃ¼ÅŸ)\n",
    "\n",
    "## Ä°Ã§erik\n",
    "1. [Gerekli KÃ¼tÃ¼phanelerin YÃ¼klenmesi](#1-gerekli-kÃ¼tÃ¼phanelerin-yÃ¼klenmesi)\n",
    "2. [KonfigÃ¼rasyon YÃ¼kleme](#2-konfigÃ¼rasyon-yÃ¼kleme)\n",
    "3. [Veri YÃ¼kleme ve Ã–n Ä°ÅŸleme](#3-veri-yÃ¼kleme-ve-Ã¶n-iÅŸleme)\n",
    "4. [TLOB Model Entegrasyonu](#4-tlob-model-entegrasyonu)\n",
    "5. [Model EÄŸitimi](#5-model-eÄŸitimi)\n",
    "6. [Model DeÄŸerlendirmesi](#6-model-deÄŸerlendirmesi)\n",
    "7. [Tahminler ve GÃ¶rselleÅŸtirme](#7-tahminler-ve-gÃ¶rselleÅŸtirme)\n",
    "8. [SonuÃ§lar ve Analiz](#8-sonuÃ§lar-ve-analiz)\n",
    "\n",
    "## âš ï¸ Ã–nemli Not\n",
    "Bu notebook'u hÃ¼creleri sÄ±rayla Ã§alÄ±ÅŸtÄ±rÄ±n. Her hÃ¼cre Ã¶nceki hÃ¼crelerin tamamlanmasÄ±nÄ± bekler."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d34124",
   "metadata": {},
   "source": [
    "## 1. Gerekli KÃ¼tÃ¼phanelerin YÃ¼klenmesi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708c9a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temel kÃ¼tÃ¼phaneler\n",
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "import warnings\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# GÃ¶rselleÅŸtirme kÃ¼tÃ¼phaneleri\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib import rcParams\n",
    "\n",
    "# Proje kÃ¶k dizinini bul ve Python path'ine ekle\n",
    "# Notebook'un bulunduÄŸu dizinden bir Ã¼st dizine Ã§Ä±k (proje kÃ¶kÃ¼)\n",
    "project_root = os.path.dirname(os.path.abspath('.'))\n",
    "# project_root = os.path.dirname(notebook_dir)  # notebooks/ dizininden bir Ã¼st\n",
    "sys.path.append(project_root)\n",
    "\n",
    "# UyarÄ±larÄ± kapat\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Matplotlib ayarlarÄ±\n",
    "plt.style.use('seaborn-v0_8')\n",
    "rcParams['figure.figsize'] = (12, 8)\n",
    "rcParams['font.size'] = 10\n",
    "\n",
    "print(\"âœ… KÃ¼tÃ¼phaneler baÅŸarÄ±yla yÃ¼klendi!\")\n",
    "print(f\"ğŸ“ Proje kÃ¶k dizini: {project_root}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9659ab9",
   "metadata": {},
   "source": [
    "## 2. KonfigÃ¼rasyon YÃ¼kleme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9b7232",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_config():\n",
    "    \"\"\"KonfigÃ¼rasyon dosyasÄ±nÄ± yÃ¼kle\"\"\"\n",
    "    # Proje kÃ¶k dizinindeki config dosyasÄ±nÄ± kullan\n",
    "    config_path = os.path.join(project_root, 'config', 'config.yaml')\n",
    "    \n",
    "    if not os.path.exists(config_path):\n",
    "        # Alternatif olarak mevcut dizinde ara\n",
    "        alt_config_path = 'config/config.yaml'\n",
    "        if os.path.exists(alt_config_path):\n",
    "            config_path = alt_config_path\n",
    "        else:\n",
    "            raise FileNotFoundError(f\"KonfigÃ¼rasyon dosyasÄ± bulunamadÄ±: {config_path}\")\n",
    "    \n",
    "    print(f\"ğŸ“‚ KonfigÃ¼rasyon dosyasÄ± yÃ¼kleniyor: {config_path}\")\n",
    "    with open(config_path, 'r') as file:\n",
    "        return yaml.safe_load(file)\n",
    "\n",
    "# KonfigÃ¼rasyonu yÃ¼kle\n",
    "config = load_config()\n",
    "print(\"ğŸ“‹ KonfigÃ¼rasyon yÃ¼klendi:\")\n",
    "print(f\"   Model tipi: {config['model']['type']}\")\n",
    "print(f\"   Hidden dim: {config['model']['hidden_dim']}\")\n",
    "print(f\"   Sequence size: {config['model']['seq_size']}\")\n",
    "print(f\"   Learning rate: {config['training']['learning_rate']}\")\n",
    "print(f\"   Batch size: {config['training']['batch_size']}\")\n",
    "print(f\"   Epochs: {config['training']['epochs']}\")\n",
    "\n",
    "# Gerekli dizinleri oluÅŸtur\n",
    "models_dir = os.path.join(project_root, 'models')\n",
    "results_dir = os.path.join(project_root, 'results')\n",
    "os.makedirs(models_dir, exist_ok=True)\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "print(\"âœ… Gerekli dizinler oluÅŸturuldu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee20b925",
   "metadata": {},
   "source": [
    "## 3. Veri YÃ¼kleme ve Ã–n Ä°ÅŸleme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26784ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veri yÃ¼kleme sÄ±nÄ±fÄ±nÄ± import et\n",
    "from src.data_loader import LOBDataLoader\n",
    "\n",
    "# Veri dosyasÄ±nÄ± bul\n",
    "data_source = config.get('data', {}).get('data_source', 'data/*.csv')\n",
    "\n",
    "# Proje kÃ¶k dizinindeki data klasÃ¶rÃ¼nÃ¼ kontrol et\n",
    "if data_source.endswith('*.csv'):\n",
    "    # Ã–nce proje kÃ¶k dizininde ara\n",
    "    data_files = glob.glob(os.path.join(project_root, 'data', '*.csv'))\n",
    "    if not data_files:\n",
    "        # Alternatif olarak mevcut dizinde ara\n",
    "        data_files = glob.glob('data/*.csv')\n",
    "    \n",
    "    if not data_files:\n",
    "        raise FileNotFoundError(\"âŒ Data dizininde CSV dosyasÄ± bulunamadÄ±!\")\n",
    "    data_path = data_files[0]\n",
    "else:\n",
    "    # Mutlak yol kullan\n",
    "    if not os.path.isabs(data_source):\n",
    "        data_path = os.path.join(project_root, data_source)\n",
    "    else:\n",
    "        data_path = data_source\n",
    "    \n",
    "    if not os.path.exists(data_path):\n",
    "        raise FileNotFoundError(f\"âŒ Veri dosyasÄ± bulunamadÄ±: {data_path}\")\n",
    "\n",
    "print(f\"ğŸ“Š Veri yÃ¼kleniyor: {data_path}\")\n",
    "\n",
    "# Veriyi yÃ¼kle\n",
    "data_loader = LOBDataLoader(data_path)\n",
    "df = data_loader.load_data()\n",
    "\n",
    "print(f\"âœ… Veri yÃ¼klendi: {len(df)} satÄ±r, {len(df.columns)} sÃ¼tun\")\n",
    "print(f\"ğŸ“… Tarih aralÄ±ÄŸÄ±: {df['DateTime'].min()} - {df['DateTime'].max()}\")\n",
    "print(f\"ğŸ“ˆ Sembol: {data_loader.symbol}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b0cc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veri Ã¶zeti\n",
    "print(\"ğŸ“Š Veri Ã–zeti:\")\n",
    "print(\"=\" * 50)\n",
    "print(df.info())\n",
    "print(\"\\nğŸ“ˆ Ä°lk 5 satÄ±r:\")\n",
    "print(df.head())\n",
    "print(\"\\nğŸ“‰ Son 5 satÄ±r:\")\n",
    "print(df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ca9d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veri istatistikleri\n",
    "print(\"ğŸ“Š Veri Ä°statistikleri:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Mid price hesapla\n",
    "df['mid_price'] = (df['Level 1 Bid Price'] + df['Level 1 Ask Price']) / 2\n",
    "\n",
    "# Fiyat istatistikleri\n",
    "print(f\"ğŸ’° Mid Price Ä°statistikleri:\")\n",
    "print(f\"   Ortalama: {df['mid_price'].mean():.4f}\")\n",
    "print(f\"   Standart Sapma: {df['mid_price'].std():.4f}\")\n",
    "print(f\"   Minimum: {df['mid_price'].min():.4f}\")\n",
    "print(f\"   Maksimum: {df['mid_price'].max():.4f}\")\n",
    "print(f\"   Medyan: {df['mid_price'].median():.4f}\")\n",
    "\n",
    "# Eksik deÄŸerler\n",
    "print(f\"\\nğŸ” Eksik DeÄŸerler:\")\n",
    "missing_data = df.isnull().sum()\n",
    "print(missing_data[missing_data > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77db0f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fiyat grafiÄŸi\n",
    "plt.figure(figsize=(15, 8))\n",
    "plt.plot(df['DateTime'], df['mid_price'], linewidth=1, alpha=0.8)\n",
    "plt.title(f'{data_loader.symbol} Mid Price Zaman Serisi', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Tarih', fontsize=12)\n",
    "plt.ylabel('Mid Price (TL)', fontsize=12)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Fiyat daÄŸÄ±lÄ±mÄ±\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(df['mid_price'], bins=50, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "plt.title('Mid Price DaÄŸÄ±lÄ±mÄ±', fontweight='bold')\n",
    "plt.xlabel('Mid Price (TL)')\n",
    "plt.ylabel('Frekans')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.boxplot(df['mid_price'])\n",
    "plt.title('Mid Price Box Plot', fontweight='bold')\n",
    "plt.ylabel('Mid Price (TL)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43d3bc6",
   "metadata": {},
   "source": [
    "## 4. TLOB Model Entegrasyonu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97fb1db3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¤– TLOB model entegrasyonu baÅŸlatÄ±lÄ±yor...\n",
      "   Hidden dim: 64\n",
      "   Num layers: 3\n",
      "   Sequence size: 64\n",
      "   Learning rate: 0.0001\n",
      "   Batch size: 512\n"
     ]
    }
   ],
   "source": [
    "# TLOB entegrasyonunu import et\n",
    "from src.tlob_integration import TLOBIntegration\n",
    "\n",
    "# TLOB konfigÃ¼rasyonu\n",
    "tlob_config = {\n",
    "    'hidden_dim': config['model']['hidden_dim'],\n",
    "    'num_layers': config['model']['num_layers'],\n",
    "    'seq_size': config['model']['seq_size'],\n",
    "    'num_heads': config['model'].get('num_heads', 1),\n",
    "    'is_sin_emb': config['model'].get('is_sin_emb', True),\n",
    "    'lr': config['training']['learning_rate'],\n",
    "    'batch_size': config['training']['batch_size'],\n",
    "    'horizon': config['model']['horizon'],\n",
    "    'forecast_days': config['model']['forecast_days'],\n",
    "    'early_stopping_patience': config['training']['early_stopping_patience'],\n",
    "    'min_delta': config['training'].get('min_delta', 0.001),\n",
    "    'data': {\n",
    "        'train_split': 0.72,\n",
    "        'val_split': 0.18,\n",
    "        'test_split': 0.10\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"ğŸ¤– TLOB model entegrasyonu baÅŸlatÄ±lÄ±yor...\")\n",
    "print(f\"   Hidden dim: {tlob_config['hidden_dim']}\")\n",
    "print(f\"   Num layers: {tlob_config['num_layers']}\")\n",
    "print(f\"   Sequence size: {tlob_config['seq_size']}\")\n",
    "print(f\"   Learning rate: {tlob_config['lr']}\")\n",
    "print(f\"   Batch size: {tlob_config['batch_size']}\")\n",
    "\n",
    "# TLOB entegrasyonunu baÅŸlat\n",
    "tlob_integration = TLOBIntegration(tlob_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f38ae5e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ Veri TLOB modeli iÃ§in hazÄ±rlanÄ±yor...\n",
      "ğŸ“Š Price Analysis:\n",
      "   Bid Price range: 69.00 - 71.50\n",
      "   Ask Price range: 69.05 - 71.55\n",
      "   Mid Price range: 69.03 - 71.53\n",
      "   Sample mid prices: [70.85, 70.875, 70.92500000000001, 70.92500000000001, 70.92500000000001]\n",
      "ğŸ“Š Data Split Information:\n",
      "   Total features: 28,784\n",
      "   Train features: 20,724 (72%)\n",
      "   Val features: 5,181 (18%)\n",
      "   Test features: 2,879 (10%)\n",
      "   Data source: /Users/tolgacoskun-mac/Source/tlob-training/data/2025-07-11-AKBNK-10.csv\n",
      "âœ… Veri hazÄ±rlandÄ±: 47 Ã¶zellik\n",
      "\n",
      "ğŸ—ï¸ Model oluÅŸturuluyor...\n",
      "âœ… Model oluÅŸturuldu:\n",
      "   Toplam parametre: 2,172,358\n",
      "   EÄŸitilebilir parametre: 2,172,358\n",
      "   Model boyutu: 8.29 MB\n"
     ]
    }
   ],
   "source": [
    "# Veriyi TLOB iÃ§in hazÄ±rla\n",
    "print(\"ğŸ”„ Veri TLOB modeli iÃ§in hazÄ±rlanÄ±yor...\")\n",
    "num_features = tlob_integration.prepare_data(data_path)\n",
    "print(f\"âœ… Veri hazÄ±rlandÄ±: {num_features} Ã¶zellik\")\n",
    "\n",
    "# Model oluÅŸtur\n",
    "print(\"\\nğŸ—ï¸ Model oluÅŸturuluyor...\")\n",
    "model = tlob_integration.create_model(num_features)\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"âœ… Model oluÅŸturuldu:\")\n",
    "print(f\"   Toplam parametre: {total_params:,}\")\n",
    "print(f\"   EÄŸitilebilir parametre: {trainable_params:,}\")\n",
    "print(f\"   Model boyutu: {total_params * 4 / 1024 / 1024:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453e43da",
   "metadata": {},
   "source": [
    "## 5. Model EÄŸitimi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21563ba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ‹ï¸ Model eÄŸitimi baÅŸlÄ±yor...\n",
      "============================================================\n",
      "ğŸ“Š EÄŸitim parametreleri:\n",
      "   Maksimum epoch: 1\n",
      "   Learning rate: 0.0001\n",
      "   Batch size: 512\n",
      "   Early stopping patience: 15\n",
      "   Min delta: 0.001\n",
      "ğŸš€ Starting training with early stopping (patience: 15, min_delta: 0.001)\n",
      "ğŸ“Š Training for max 1 epochs with learning rate: 0.0001\n"
     ]
    }
   ],
   "source": [
    "# Model eÄŸitimi\n",
    "print(\"ğŸ‹ï¸ Model eÄŸitimi baÅŸlÄ±yor...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "max_epochs = config['training']['epochs']\n",
    "print(f\"ğŸ“Š EÄŸitim parametreleri:\")\n",
    "print(f\"   Maksimum epoch: {max_epochs}\")\n",
    "print(f\"   Learning rate: {config['training']['learning_rate']}\")\n",
    "print(f\"   Batch size: {config['training']['batch_size']}\")\n",
    "print(f\"   Early stopping patience: {config['training']['early_stopping_patience']}\")\n",
    "print(f\"   Min delta: {config['training'].get('min_delta', 0.001)}\")\n",
    "\n",
    "# EÄŸitimi baÅŸlat\n",
    "training_history = tlob_integration.train_model(max_epochs=max_epochs)\n",
    "print(\"\\nâœ… EÄŸitim tamamlandÄ±!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a61f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EÄŸitim geÃ§miÅŸini gÃ¶rselleÅŸtir\n",
    "if 'training_history' in locals() and training_history:\n",
    "    print(\"ğŸ“ˆ EÄŸitim geÃ§miÅŸi gÃ¶rselleÅŸtiriliyor...\")\n",
    "    \n",
    "    # EÄŸitim ve validasyon loss'larÄ±\n",
    "    train_losses = [h['train_loss'] for h in training_history]\n",
    "    val_losses = [h['val_loss'] for h in training_history]\n",
    "    epochs = range(1, len(train_losses) + 1)\n",
    "    \n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, train_losses, 'b-', label='EÄŸitim Loss', linewidth=2)\n",
    "    plt.plot(epochs, val_losses, 'r-', label='Validasyon Loss', linewidth=2)\n",
    "    plt.title('EÄŸitim ve Validasyon Loss', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # EÄŸitim ve validasyon accuracy'leri\n",
    "    train_accs = [h.get('train_acc', 0) for h in training_history]\n",
    "    val_accs = [h.get('val_acc', 0) for h in training_history]\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, train_accs, 'b-', label='EÄŸitim Accuracy', linewidth=2)\n",
    "    plt.plot(epochs, val_accs, 'r-', label='Validasyon Accuracy', linewidth=2)\n",
    "    plt.title('EÄŸitim ve Validasyon Accuracy', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Son epoch bilgileri\n",
    "    print(f\"\\nğŸ“Š Son Epoch Bilgileri:\")\n",
    "    print(f\"   Epoch: {len(training_history)}\")\n",
    "    print(f\"   Son eÄŸitim loss: {train_losses[-1]:.4f}\")\n",
    "    print(f\"   Son validasyon loss: {val_losses[-1]:.4f}\")\n",
    "    print(f\"   Son eÄŸitim accuracy: {train_accs[-1]:.4f}\")\n",
    "    print(f\"   Son validasyon accuracy: {val_accs[-1]:.4f}\")\n",
    "else:\n",
    "    print(\"âš ï¸ EÄŸitim geÃ§miÅŸi bulunamadÄ±. Ã–nce model eÄŸitimini tamamlayÄ±n.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084bc2a1",
   "metadata": {},
   "source": [
    "## 6. Model DeÄŸerlendirmesi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4dbdd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# En iyi modeli yÃ¼kle\n",
    "print(\"ğŸ“¥ En iyi model yÃ¼kleniyor...\")\n",
    "model_path = os.path.join(project_root, 'models', 'best_tlob_model.pth')\n",
    "try:\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    tlob_integration.model = model\n",
    "    print(\"âœ… En iyi model yÃ¼klendi\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"âš ï¸ En iyi model dosyasÄ± bulunamadÄ±: {model_path}\")\n",
    "    print(\"Ã–nce model eÄŸitimini tamamlayÄ±n.\")\n",
    "    raise\n",
    "\n",
    "# Model performansÄ±nÄ± deÄŸerlendir\n",
    "print(\"\\nğŸ§ª Model performansÄ± deÄŸerlendiriliyor...\")\n",
    "test_metrics = tlob_integration.evaluate_model()\n",
    "\n",
    "print(\"\\nğŸ“Š Test Metrikleri:\")\n",
    "print(\"=\" * 50)\n",
    "for metric_name, metric_value in test_metrics.items():\n",
    "    if isinstance(metric_value, float):\n",
    "        print(f\"   {metric_name}: {metric_value:.4f}\")\n",
    "    else:\n",
    "        print(f\"   {metric_name}: {metric_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ae000b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test metriklerini kaydet\n",
    "tlob_integration.save_test_metrics(test_metrics)\n",
    "print(\"âœ… Test metrikleri kaydedildi\")\n",
    "\n",
    "# Metrikleri gÃ¶rselleÅŸtir\n",
    "print(\"\\nğŸ“Š Metrik gÃ¶rselleÅŸtirmeleri oluÅŸturuluyor...\")\n",
    "\n",
    "# SÄ±nÄ±f daÄŸÄ±lÄ±mÄ±\n",
    "if 'class_distribution' in test_metrics:\n",
    "    class_dist = test_metrics['class_distribution']\n",
    "    classes = ['DÃ¼ÅŸÃ¼ÅŸ', 'Sabit', 'YÃ¼kseliÅŸ']\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    bars = plt.bar(classes, [class_dist.get(str(i), 0) for i in range(3)], \n",
    "                   color=['red', 'gray', 'green'], alpha=0.7)\n",
    "    plt.title('Test Verisi SÄ±nÄ±f DaÄŸÄ±lÄ±mÄ±', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('SÄ±nÄ±f')\n",
    "    plt.ylabel('Ã–rnek SayÄ±sÄ±')\n",
    "    \n",
    "    # DeÄŸerleri Ã§ubuklarÄ±n Ã¼zerine yaz\n",
    "    for bar, value in zip(bars, [class_dist.get(str(i), 0) for i in range(3)]):\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, \n",
    "                str(value), ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Confusion matrix\n",
    "if 'confusion_matrix' in test_metrics:\n",
    "    cm = test_metrics['confusion_matrix']\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=classes, yticklabels=classes)\n",
    "    plt.title('Confusion Matrix', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Tahmin Edilen SÄ±nÄ±f')\n",
    "    plt.ylabel('GerÃ§ek SÄ±nÄ±f')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4434a75",
   "metadata": {},
   "source": [
    "## 7. Tahminler ve GÃ¶rselleÅŸtirme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8dcbd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test verisi Ã¼zerinde tahminler yap\n",
    "print(\"ğŸ”® Tahminler yapÄ±lÄ±yor...\")\n",
    "\n",
    "# Test verisi al\n",
    "test_loader = tlob_integration.data_module.test_dataloader()\n",
    "test_batch = next(iter(test_loader))\n",
    "test_data = test_batch[0]  # Ä°lk batch verisi\n",
    "test_labels = test_batch[1]  # Ä°lk batch etiketleri\n",
    "\n",
    "# Tek tahmin\n",
    "print(\"\\nğŸ“Š Tek tahmin Ã¶rneÄŸi:\")\n",
    "prediction, probabilities = tlob_integration.predict(test_data[0].numpy())\n",
    "direction_map = {0: \"YÃ¼kseliÅŸ\", 1: \"Sabit\", 2: \"DÃ¼ÅŸÃ¼ÅŸ\"}\n",
    "print(f\"   Tahmin: {direction_map[prediction]} (SÄ±nÄ±f {prediction})\")\n",
    "print(f\"   GÃ¼ven: {np.max(probabilities):.2%}\")\n",
    "print(f\"   TÃ¼m olasÄ±lÄ±klar: {probabilities}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b367aac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# N-gÃ¼nlÃ¼k tahmin\n",
    "forecast_days = config['model']['forecast_days']\n",
    "print(f\"\\nğŸ“… {forecast_days} gÃ¼nlÃ¼k tahmin oluÅŸturuluyor...\")\n",
    "forecast = tlob_integration.predict_days(test_data.numpy())\n",
    "\n",
    "# Tahmin sonuÃ§larÄ±nÄ± gÃ¶ster\n",
    "print(f\"\\n{forecast_days} GÃ¼nlÃ¼k Mid Price Tahmin SonuÃ§larÄ±:\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for day_result in forecast:\n",
    "    day = day_result['day']\n",
    "    pred = day_result['prediction']\n",
    "    conf = day_result['confidence']\n",
    "    mid_price = day_result['mid_price'].item() if hasattr(day_result['mid_price'], 'item') else float(day_result['mid_price'])\n",
    "    change_pct = day_result['price_change_pct'].item() if hasattr(day_result['price_change_pct'], 'item') else float(day_result['price_change_pct'])\n",
    "    direction = direction_map[pred]\n",
    "    \n",
    "    print(f\"  GÃ¼n {day:2d}: {direction:8s} | Mid Price: {mid_price:8.4f} | DeÄŸiÅŸim: {change_pct:+6.2f}% | GÃ¼ven: {conf:6.2%}\")\n",
    "\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e1da99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tahmin gÃ¶rselleÅŸtirmeleri\n",
    "print(\"\\nğŸ“Š Tahmin gÃ¶rselleÅŸtirmeleri oluÅŸturuluyor...\")\n",
    "\n",
    "# GÃ¶rselleÅŸtirme sÄ±nÄ±fÄ±nÄ± import et\n",
    "from src.visualization import LOBVisualizer\n",
    "viz = LOBVisualizer()\n",
    "\n",
    "# EÄŸitim geÃ§miÅŸi\n",
    "print(\"ğŸ“ˆ EÄŸitim geÃ§miÅŸi Ã§iziliyor...\")\n",
    "viz.plot_training_history(tlob_integration)\n",
    "\n",
    "# Fiyat evrimi\n",
    "print(\"ğŸ“Š Fiyat evrimi Ã§iziliyor...\")\n",
    "viz.plot_price_evolution(data_loader)\n",
    "\n",
    "# Tahmin grafiÄŸi\n",
    "print(\"ğŸ”® Tahmin grafiÄŸi Ã§iziliyor...\")\n",
    "viz.plot_forecast(forecast)\n",
    "\n",
    "print(\"âœ… TÃ¼m gÃ¶rselleÅŸtirmeler tamamlandÄ±!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae55711",
   "metadata": {},
   "source": [
    "## 8. SonuÃ§lar ve Analiz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b935c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proje Ã¶zeti\n",
    "print(\"ğŸ‰ TLOB Fiyat Tahmin Projesi TamamlandÄ±!\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"ğŸ“Š Proje Ã–zeti:\")\n",
    "print(f\"   Veri kaynaÄŸÄ±: {data_path}\")\n",
    "print(f\"   Toplam veri: {len(df):,} satÄ±r\")\n",
    "print(f\"   Model tipi: {config['model']['type']}\")\n",
    "print(f\"   Model parametreleri: {total_params:,}\")\n",
    "print(f\"   EÄŸitim epoch'larÄ±: {len(training_history) if 'training_history' in locals() else 'N/A'}\")\n",
    "print(f\"   Test accuracy: {test_metrics.get('accuracy', 'N/A'):.4f}\")\n",
    "print(f\"   Test precision: {test_metrics.get('precision', 'N/A'):.4f}\")\n",
    "print(f\"   Test recall: {test_metrics.get('recall', 'N/A'):.4f}\")\n",
    "print(f\"   Test f1_score: {test_metrics.get('f1_score', 'N/A'):.4f}\")\n",
    "\n",
    "print(f\"\\nğŸ“ Kaydedilen Dosyalar:\")\n",
    "print(f\"   Model: {os.path.join(project_root, 'models', 'best_tlob_model.pth')}\")\n",
    "print(f\"   Test metrikleri: {os.path.join(project_root, 'results', 'test_metrics.json')}\")\n",
    "print(f\"   GÃ¶rselleÅŸtirmeler: {os.path.join(project_root, 'results')}\")\n",
    "\n",
    "print(f\"\\nğŸ”® Tahmin Ã–zeti:\")\n",
    "up_count = sum(1 for f in forecast if f['prediction'] == 0)\n",
    "stable_count = sum(1 for f in forecast if f['prediction'] == 1)\n",
    "down_count = sum(1 for f in forecast if f['prediction'] == 2)\n",
    "print(f\"   YÃ¼kseliÅŸ tahmini: {up_count} gÃ¼n\")\n",
    "print(f\"   Sabit tahmini: {stable_count} gÃ¼n\")\n",
    "print(f\"   DÃ¼ÅŸÃ¼ÅŸ tahmini: {down_count} gÃ¼n\")\n",
    "\n",
    "print(\"\\nâœ… Analiz tamamlandÄ±! SonuÃ§lar 'results/' dizininde kaydedildi.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0fbcb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SonuÃ§larÄ± JSON olarak kaydet\n",
    "final_results = {\n",
    "    'project_info': {\n",
    "        'name': 'TLOB Price Prediction Project',\n",
    "        'date': datetime.now().isoformat(),\n",
    "        'data_source': data_path,\n",
    "        'total_data_points': len(df),\n",
    "        'model_type': config['model']['type']\n",
    "    },\n",
    "    'model_config': config,\n",
    "    'training_summary': {\n",
    "        'total_epochs': len(training_history) if 'training_history' in locals() else 0,\n",
    "        'final_train_loss': training_history[-1]['train_loss'] if 'training_history' in locals() and training_history else None,\n",
    "        'final_val_loss': training_history[-1]['val_loss'] if 'training_history' in locals() and training_history else None,\n",
    "        'model_parameters': total_params\n",
    "    },\n",
    "    'test_metrics': test_metrics,\n",
    "    'forecast_summary': {\n",
    "        'forecast_days': forecast_days,\n",
    "        'predictions': [{\n",
    "            'day': f['day'],\n",
    "            'prediction': direction_map[f['prediction']],\n",
    "            'confidence': float(f['confidence']),\n",
    "            'mid_price': float(f['mid_price']),\n",
    "            'price_change_pct': float(f['price_change_pct'])\n",
    "        } for f in forecast]\n",
    "    }\n",
    "}\n",
    "\n",
    "# JSON dosyasÄ±na kaydet\n",
    "results_file = os.path.join(project_root, 'results', 'final_analysis_results.json')\n",
    "with open(results_file, 'w', encoding='utf-8') as f:\n",
    "    json.dump(final_results, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"âœ… Final analiz sonuÃ§larÄ± kaydedildi: {results_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
